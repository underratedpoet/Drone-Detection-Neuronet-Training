# Drone-Detection-Neuronet-Training
Решение задачи покадрового обнаружения объекта(ов) (в частности, разных моделей дронов) осуществлялось с помощью обучения нейросети.

![image](https://user-images.githubusercontent.com/103249547/180995001-a2cdcd87-e92b-40d1-ae09-b06ee4c886ac.png)
## Подготовка к обучению


Обучение нейросети и сам процесс обнаружения написан на языке Python 3.7 в среде PyCharm с помощью библиотек машинного обучения и компьютерного зрения - Tensorflow и ImageAI соответственно. Для их установки использовались система управления пакетами pip и дистирибутив anaconda.

Команды терминала для установки библиотек и зависимостей:
```
pip install tensorflow-gpu==2.4.0
```
или
```
pip install tensorflow==2.4.0
```
в зависимости от возможности компьютера осуществлять обучение, используя графический процессор. Для этого требуется архитектура параллельных вычислений CUDA (версии 11.0) а так же cuDNN (версии 8.0):
```
conda create --name tf python=3.7
conda activate tf
conda install -c conda-forge cudatoolkit=11.0 cudnn=8.0
```
![image](https://user-images.githubusercontent.com/103249547/180806660-21401264-5aa9-4974-8cd1-ec0a156d0b97.png)

Другие зависимости ImageAI:
```
pip install keras==2.4.3 numpy==1.19.3 pillow==7.0.0 scipy==1.4.1 h5py==2.10.0 matplotlib==3.3.2 opencv-python keras-resnet==0.2.0
```
И установка самого ImageAI:

```
pip install imageai --upgrade
```

Далее, с помощью [документации к ImageAI](https://github.com/OlafenwaMoses/ImageAI) был написан код обучения нейросети:
```Python
from imageai.Detection.Custom import DetectionModelTrainer

trainer = DetectionModelTrainer()
trainer.setModelTypeAsYOLOv3()
trainer.setDataDirectory(data_directory="drone")
trainer.setTrainConfig(object_names_array=["drone"], batch_size=4, num_experiments=20, train_from_pretrained_model="pretrained-yolov3.h5")

trainer.trainModel()
```

![image](https://user-images.githubusercontent.com/103249547/180997774-bc4e67f2-8f4e-4130-abd9-8e2f4b9184a0.png)
Для корректной работы кода необходимо в папке с .py файлом расположить директорию с именем как у объекта, имеющую данную структуру. 

В данном случае нейросеть должна находить в кадре объект типа БПЛА. Как исходная сеть, была выбрана предобученная модель pretrained-yolov3 на основе YOLOv3. Последняя за счет своей архитектуры является одной из самой эффективных и быстродействующих нейросетей для обнаружения объектов. Параметр скорости обнаружения крайне важен в условиях работы в реальном времени. 
Кроме этого, для первого этапа обучения с сайта Kaggle был скачан и отредактирован датасет с изображениями БПЛА и приложенными к ним xml файлами, хранящими данные о местоположениях объектов.

## Процесс обучения

Первая попытка запустить обучение сети была предпринята на ноутбуке без поддержки CUDA. Несмотря на, в целом, неплохую производительность, устройство не могло в полной мере использовать свои ресурсы, поэтому обучение длилось слишком долго и могло, в среднем, занять до четырех суток при размере датасета примерно в тысячу изображений.

После этого код был перенесен в облачную среду Google Colab.
![image](https://user-images.githubusercontent.com/103249547/180948553-249eed18-d3ad-4dd0-9b2d-be3b21f01770.png)
Процесс подключения необходимых библиотек примерно такой же, плюсом здесь было отсутствие необходимости в установке и настройке CUDA, так как весь необходимый софт для работы с графическим процессором находился уже в среде.

[Cам блокнот Colab](https://colab.research.google.com/drive/1897ZgouN-mSK147_INk9b309iBTWm1si#scrollTo=6R7F-c8BcbvO). Здесь, кроме кода обучения нейросети, написан так же код обнаружения объекта на видео. Результатом работы кода являлось то же самое видео, но с выделенными на нем искомыми объектами.

```Python
from imageai.Detection.Custom import CustomVideoObjectDetection
import os

execution_path = os.getcwd()

video_detector = CustomVideoObjectDetection()
video_detector.setModelTypeAsYOLOv3()
video_detector.setModelPath("detection_model-ex-010--loss-0018.309.h5")
video_detector.setJsonPath("detection_config.json")
video_detector.loadModel()

video_detector.detectObjectsFromVideo(input_file_path="drone.mp4",
                                          output_file_path=os.path.join(execution_path, "detected"),
                                          frames_per_second=20,
                                          minimum_percentage_probability=40,
                                          log_progress=True)
```
(после обучения создаются .h5 и .json файлы, которые затем и используются при обнаружении)

Сеть успешно обучилась на первом датасете, а затем на втором, созданном уже вручную, размером в ~500 изображений. Новой проблемой в процессе обучения оказалась довольно низкая точность сети. Потери после всего обучения опустились только до 13.3%. Кроме того, так как Colab - облачная среда с огромным количеством пользователей, в ней существуют ограничения на продолжительность сеансов, а загруженные (датасеты, модели) и созданные (новые версии моделей) файлы не сохраняются по завершении сеанса. Так, во время использования среды сеанс часто завершался на середине обучения, а если обучение и было завершено, файлы новых моделей могли не успеть сохраниться на жесткий диск. Хоть сам код и работал быстрее с использованием графического процессора, фактически обучение длилось крайне долго, так как часто поцесс приходилось начинать заново.

Следующий этап - возможность использовать стационарный компьютер с поддержкой CUDA. Здесь понадобилось подключение всего софта, описанного в первой главе. В компьютер установлена видеокарта NVIDIA Quadro RTX 4000, она позволила сильно увеличить скорость обучения нейросети, примерно до 370мс/шаг при 500мс/шаг в Colab и 10c/шаг без GPU. Карта, однако, не справилась с увеличением batch size - при любом размере больше четырех выделенной памяти процессора не хватало, и программа экстренно завершалась. Кроме этого, во время работы кода достаточно часто появляются ошибки (не мешающие, однако, процессу обучения)

![Момент запуска кода](https://user-images.githubusercontent.com/103249547/180959799-66ad31f7-3c84-48e5-8cbc-52abaa4469da.png)

Несмотря на все вышеописанное, такой способ работы с нейросетью позволил добиться увеличения скорости обучения и точности самой сети, которая, тем не менее, остается небольшой.

![image](https://user-images.githubusercontent.com/103249547/180995183-fb4403cb-cd5c-4fcc-8f0d-ae3b30325beb.png)
![image](https://user-images.githubusercontent.com/103249547/180995233-dbf026cd-49ba-4500-a796-d1cba680467e.png)


## Возможные решения проблем
Две главные трудности, существующие на данном этапе обучения, это высокие потери и невозможность установить высокий (8, 16) batch size (что тоже влияет на размер потерь)

Из предложений - изменить подход к созданию датасетов. Все это время нейросети "скармливались" изображения абсолютно любых БПЛА, в которых она должна была найти общие черты объекта "drone". Это, возможно, мешает сети обобщить данные, так как формы объектов, их размеры и положения сильно разнятся. В данном случае может помочь определение разных моделей дронов для сети как разных объектов. Кроме этого, нейросети крайне важен контекст, условно говоря, задний фон. Это значит, что для большей точности необходимо выбирать изображения БПЛА именно в тех средах, в которых будет применяться сеть.

Следующий этап улучшения точности - увеличение самих размеров датасетов. Это, однако, требует больших затрат во времени как в смысле их создания, так и в смысле процесса обучения (хотя для обучения все файлы можно разделить на небольшие группы и отдавать нейросети по очереди, это так же поможет контролировать промежуточные результаты обучения)

Для увеличения batch size можно поэкспериментировать с версиями софта, который, возможно, сейчас использует ресурсы GPU нерационально, либо изменить саму архитектуру сети, уменьшив количество скрытых слоев, что, однако может только увеличить потери.

[Обученная модель и json-файл](https://drive.google.com/drive/folders/1gmlP6D4Qz3kloXxdDgaNSKDKK_WzA8xI?usp=sharing)
